# -*- coding: utf-8 -*-
"""Recommendation System 1.2

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1EzSxsxZ5s-ok1afaKL-QJkJ1NI3htCyi

Dicoding IDCamp 2024: Machine Learning Terapan

Model Sistem Rekomendasi

Nama: Nugroho Adi Wirapratama

Email: adiwira009@gmail.com

LinkedIn: https://www.linkedin.com/in/nug-adiwira/

Github: https://github.com/adiwira09

# Download dataset
"""

import kagglehub
import shutil

# Download latest version
path = kagglehub.dataset_download("aprabowo/indonesia-tourism-destination")
shutil.move(path, '/content')

"""Dataset information:
1. tourism_ with _id.csv : berisi informasi tentang objek wisata di 5 kota besar di Indonesia dengan total sekitar 400 tempat wisata.
2. user.csv : berisi data pengguna dummy untuk membuat fitur rekomendasi berdasarkan pengguna.
3. tourism_rating.csv : berisi 3 kolom, yaitu pengguna, tempat wisata, dan rating yang diberikan, digunakan untuk membuat sistem rekomendasi berdasarkan rating.
4. package_tourism.csv : berisi rekomendasi tempat wisata terdekat berdasarkan waktu, biaya, dan rating.

# Import library
"""

!pip install Sastrawi -q

!pip uninstall numpy -y
!pip install numpy==1.26.4 -q

!pip install scikit-surprise==1.1.4 -q

"""Restart kernel terlebih dahulu"""

import re
import numpy as np
import pandas as pd

import seaborn as sns
import matplotlib.pyplot as plt

from sklearn.metrics.pairwise import cosine_similarity
from sklearn.feature_extraction.text import TfidfVectorizer

from surprise import SVD, Dataset, Reader
from surprise.model_selection import train_test_split
from surprise import accuracy
from surprise.accuracy import rmse, mae

import nltk
from nltk.corpus import stopwords
from Sastrawi.Stemmer.StemmerFactory import StemmerFactory

import warnings
warnings.filterwarnings('ignore')

nltk.download('stopwords')

"""# Load data"""

tourism = pd.read_csv('indonesia-tourism-destination/tourism_with_id.csv')
rating = pd.read_csv('indonesia-tourism-destination/tourism_rating.csv')

tourism = pd.read_csv('1/tourism_with_id.csv')
rating = pd.read_csv('1/tourism_rating.csv')

# Merge dataset
df = pd.merge(rating, tourism, on='Place_Id', how='left')

# Delete kolom yang tidak diketahui dan tidak diperlukan
df = df.drop(['Unnamed: 11','Unnamed: 12', 'Time_Minutes', 'Coordinate',	'Lat',	'Long', 'Place_Ratings'], axis=1)

df.shape

"""# Data understanding"""

df.head()

"""**Kolom Information:**
- User_Id : user_id.
- Place_Id : id dari Place_Name.
- Place_Name : nama tempat destinasi.
- Description : teks deskripsi tentang destinasi.
- Category : kategori dari destinasi.
- City : lokasi kota dari destinasi.
- Price : harga tiket masuk destinasi.
- Rating : rating yang diberikan User_Id terhadap destinasi.
"""

df.info()

df.describe()

top_places_rating = df.groupby('Place_Name')['Rating'].mean().sort_values(ascending=False).head(10)

# Visualizing with seaborn
plt.figure(figsize=(10, 6))
sns.barplot(x=top_places_rating.values, y=top_places_rating.index, palette='viridis')
plt.title('Top 10 Places by Average Rating')
plt.xlabel('Average Rating')
plt.ylabel('Place Name')
plt.show()

"""Wisata Kuliner Pecenongan menduduki peringkat pertama dengan rating tertinggi, diikuti oleh Desa Wisata Sungai Code Jogja Kota dan Freedom Library."""

df_rating_price = df.groupby('Place_Name').agg(
    avg_rating=('Rating', 'mean'),
    price=('Price', 'first')
).reset_index()

plt.figure(figsize=(10, 6))
sns.scatterplot(x='price', y='avg_rating', data=df_rating_price)
plt.title('Scatter Plot: Harga vs Rating')
plt.xlabel('Harga')
plt.ylabel('Rating')
plt.show()

"""Dari scatter plot, terlihat bahwa meskipun harga bervariasi, sebagian besar destinasi memiliki rating tinggi (di atas 4), namun tidak ada pola yang jelas antara harga dan rating."""

import statsmodels.api as sm

# Menambahkan konstanta untuk model regresi
X = sm.add_constant(df_rating_price['price'])
y = df_rating_price['avg_rating']

# Membuat model regresi
model = sm.OLS(y, X).fit()

# Melihat hasil ringkasan model regresi
print(model.summary())

"""Dalam analisis regresi, hasil menunjukkan bahwa koefisien untuk harga sangat kecil (7.296e-08), dan p-value sebesar 0.628 menunjukkan bahwa harga tidak berpengaruh signifikan terhadap rating destinasi wisata. Nilai R-squared yang sangat rendah (0.001) juga menegaskan bahwa harga hanya menjelaskan sedikit sekali variasi dalam rating.

**Harga tidak menjadi faktor yang signifikan dalam menentukan rating destinasi wisata.**
"""

ratings = df['Rating'].round().astype(int)
rating_counts = pd.Series(ratings).value_counts().sort_index()

plt.figure(figsize=(8, 6))
rating_counts.plot(kind='bar')
plt.title('Distribution of Ratings')
plt.xlabel('Rating')
plt.ylabel('Count')
plt.xticks(rotation=0)
plt.show()

"""Sebagian besar rating yang diterima adalah rating 4, dengan jumlah yang sangat dominan hampir mencapai 7.000. Sementara itu, rating 5 juga mendapatkan jumlah yang cukup besar, meskipun jauh lebih sedikit dibandingkan rating 4. Di sisi lain, rating 3 hampir tidak terlihat di grafik, menandakan bahwa sedikit sekali tempat yang menerima penilaian di sekitar nilai ini.

# Data preparation
"""

print("Sebelum dilakukan data preparation")

baris, kolom = df.shape
print(f"Jumlah baris: {baris}")
print(f"Jumlah kolom: {kolom}")

"""## Menghapus kolom tidak relevan"""

df = df.drop(['Price'], axis=1)

"""- Kolom price tidak digunakan oleh karena itu dihapus.
- Price tidak memberikan korelasi terhadap rating yang diberikan oleh user terhadap destinasi.
"""

# cek missing value
df.isnull().sum()

"""Tidak ada baris yang memiliki NaN value

## Drop/delete duplikat value
"""

jumlah_duplikat = df.duplicated().sum()
persentase_duplikat = (jumlah_duplikat / len(df)) * 100

print(f'Data duplikat: {jumlah_duplikat} atau {persentase_duplikat:.2f}%')

"""- Terdapat 403 data duplikat, yang merupakan 4.03% dari keseluruhan data.
- Data duplikat secara keseluruhan, bahkan secara "Description" benar-benar sama.

Oleh karena itu kita hapus semua data yang duplikat.
"""

df_clean = df.drop_duplicates()

"""## Processing text"""

stop_words = set(stopwords.words('indonesian'))
stemmer = StemmerFactory().create_stemmer()

def preprocess(text):
    text = text.lower()                                  # Lowercase
    text = re.sub(r'[^\w\s]', '', text)                  # Remove punctuation
    text = re.sub(r'\d+', '', text)                      # Remove numbers (optional)
    tokens = text.split()
    tokens = [word for word in tokens if word not in stop_words]  # Remove stopwords
    text = ' '.join(tokens)
    text = stemmer.stem(text)                            # Stemming
    return text

df_clean['Description'] = df_clean['Description'].apply(preprocess)
df_clean['City'] = df_clean['City'].apply(preprocess)
df_clean['Category'] = df_clean['Category'].apply(preprocess)

df_clean.head()

print("Setelah dilakukan data preparation")

baris, kolom = df_clean.shape
print(f"Jumlah baris: {baris}")
print(f"Jumlah kolom: {kolom}")

"""## Pemisahan data (CBF dan CF)

### CBF
"""

df_cbf = df_clean.copy()
df_cbf.drop_duplicates(subset='Place_Id', inplace=True)
df_cbf.drop(['User_Id', 'Rating'], axis=1, inplace=True)
df_cbf.reset_index(drop=True, inplace=True)
df_cbf

tfidf = TfidfVectorizer()
tfidf_matrix = tfidf.fit_transform(df_cbf['Description'])

print(tfidf_matrix.shape)

cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)
cosine_sim

"""### CF"""

df_cf = df_clean.copy()
df_cf.drop(['Place_Id', 'Description', 'City', 'Category'], axis=1, inplace=True)
df_cf

reader = Reader(rating_scale=(1, 5))
data = Dataset.load_from_df(df_cf, reader)

trainset, testset = train_test_split(data, test_size=0.2, random_state=42)

"""# Model development

## CBF
"""

def get_recommendations(query_index, n_recommendations=5):
    place_name = df_cbf['Place_Name'][query_index]
    category = df_cbf['Category'][query_index]
    city = df_cbf['City'][query_index]
    description = df_cbf['Description'][query_index]

    # Tampilkan info awal
    print(f'Destinasi: {place_name}')
    print(f'Kategori: {category}')
    print(f'Kota: {city}')
    print(f'Deskripsi: {description}\n')
    print(f'{n_recommendations} Rekomendasi:\n')

    similarity_scores = list(enumerate(cosine_sim[query_index]))

    recommendations = []
    for idx, sim_score in similarity_scores:
        if idx == query_index:
            continue  # skip diri sendiri

        # Binary match: 1 jika sama, 0 jika tidak
        category_score = 1 if df_cbf['Category'][idx] == category else 0
        city_score = 1 if df_cbf['City'][idx] == city else 0
        description_score = sim_score

        # Hitung total skor akhir
        final_score = (0.6 * description_score) + (0.25 * category_score) + (0.15 * city_score)

        recommendations.append({
            'Recommended Destination': df_cbf['Place_Name'][idx],
            'Category': df_cbf['Category'][idx],
            'City': df_cbf['City'][idx],
            'Description Similarity': round(description_score, 4),
            'Category Score': round(category_score, 4),
            'City Score': round(city_score, 4),
            'Total Score': round(final_score, 4)
        })

    # Buat DataFrame dari hasil rekomendasi dan ambil n teratas
    recommendations_df = pd.DataFrame(recommendations).sort_values(by='Total Score', ascending=False)
    return recommendations_df.head(n_recommendations)

query_index = 21
recommendations = get_recommendations(query_index, n_recommendations=10)
recommendations

"""Terlihat bahwa hampir seluruh hasil memiliki kategori yang sama (pusat belanja) dan berada di lokasi yang sama (Jakarta), dengan deskripsi yang mengandung kesamaan tematik seperti “pasar”, “belanja”, “kawasan seni”, dan “kolektor”.

## CF
"""

# Gunakan SVD untuk matrix factorization
model = SVD()
model.fit(trainset)

predictions = model.test(testset)

# Fungsi rekomendasi berdasarkan matrix factorization
def get_mf_recommendations(user_id, top_n=5):
    place_names = df_cf['Place_Name'].unique()
    rated_places = df_cf[df_cf['User_Id'] == user_id]['Place_Name'].tolist()
    unrated_places = [place for place in place_names if place not in rated_places]

    pred_ratings = []
    for place in unrated_places:
        pred = model.predict(user_id, place)
        pred_ratings.append((place, pred.est))

    sorted_preds = sorted(pred_ratings, key=lambda x: x[1], reverse=True)[:top_n]
    return pd.DataFrame(sorted_preds, columns=['Recommended Place', 'Predicted Rating'])

# Contoh pemanggilan
get_mf_recommendations(user_id=1, top_n=10)

# Evaluasi: RMSE dan MAE
rmse(predictions)
mae(predictions)

"""Dengan nilai RMSE sebesar 0.1073 dan MAE 0.0848, model memiliki kemampuan prediksi yang cukup tinggi. Artinya, sistem mampu memprediksi rating pengguna terhadap destinasi wisata dengan tingkat kesalahan yang sangat kecil — cocok untuk aplikasi nyata dalam sistem rekomendasi."""

