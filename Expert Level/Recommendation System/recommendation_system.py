# -*- coding: utf-8 -*-
"""Recommendation System 1.3

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1lOzY0ESEY6pJV1hB3jLrR82lAtVr9awJ

Dicoding IDCamp 2024: Machine Learning Terapan

Model Sistem Rekomendasi

Nama: Nugroho Adi Wirapratama

Email: adiwira009@gmail.com

LinkedIn: https://www.linkedin.com/in/nug-adiwira/

Github: https://github.com/adiwira09

# Download dataset
"""

import kagglehub
import shutil

# Download latest version
path = kagglehub.dataset_download("aprabowo/indonesia-tourism-destination")
shutil.move(path, '/content')

"""# Import library"""

!pip install Sastrawi -q

!pip uninstall numpy -y
!pip install numpy==1.26.4 -q

!pip install scikit-surprise==1.1.4 -q

"""Restart kernel terlebih dahulu"""

import re
import numpy as np
import pandas as pd

import seaborn as sns
import matplotlib.pyplot as plt

from sklearn.metrics.pairwise import cosine_similarity
from sklearn.feature_extraction.text import TfidfVectorizer

from surprise import SVD, Dataset, Reader
from surprise.model_selection import train_test_split
from surprise import accuracy
from surprise.accuracy import rmse, mae

import nltk
from nltk.corpus import stopwords
from Sastrawi.Stemmer.StemmerFactory import StemmerFactory

import warnings
warnings.filterwarnings('ignore')

nltk.download('stopwords')

"""# Load data"""

tourism = pd.read_csv('1/tourism_with_id.csv')
rating = pd.read_csv('1/tourism_rating.csv')

print(f"Data tourism\nJumlah kolom: {tourism.shape[1]}\nJumlah baris: {tourism.shape[0]}\n")
print(f"Data Rating\nJumlah kolom: {rating.shape[1]}\nJumlah baris: {rating.shape[0]}")

"""Dataset information:
1. tourism_ with _id.csv : berisi informasi tentang objek wisata di 5 kota besar di Indonesia dengan total sekitar 400 tempat wisata.
2. tourism_rating.csv : berisi 3 kolom, yaitu pengguna, tempat wisata, dan rating yang diberikan, digunakan untuk membuat sistem rekomendasi berdasarkan rating.

# Data understanding
"""

tourism.head()

"""**Kolom Information:**
- Place_Id : id dari Place_Name.
- Place_Name : nama tempat destinasi.
- Description : teks deskripsi tentang destinasi.
- Category : kategori dari destinasi.
- City : lokasi kota dari destinasi.
- Price : harga tiket masuk destinasi.
- Rating : rata-rata rating yang diberikan destinasi.
- Time_Minutes :
- Coordinate : Koordinat longitude & latitude destinasi.
- Lat : Koordinat latitude destinasi wisata.
- Long : Koordinat longitude destinasi wisata.
- Unnamed: 11 : Unknown information
- Unnamed: 12 : Unknown information
"""

rating.head()

"""**Kolom Information:**
- User_Id : user_id.
- Place_Id : id dari Place_Name.
- Place_Ratings : rating yang diberikan User_Id terhadap destinasi.
"""

tourism.info()

rating.info()

tourism.describe()

rating.describe()

tourism.isna().sum()

print(f'Jumlah data duplikat pada tourism_with_id.csv: {tourism.duplicated().sum()}')

"""Pada data tourism_with_id.csv:
- Tidak terdapat data duplikat.
- Terdapat NaN value pada kolom Time_Minutes dan Unnamed: 11
"""

rating.isna().sum()

print(f'Jumlah data duplikat pada tourism_rating.csv: {rating.duplicated().sum()}')

"""Pada data tourism_rating.csv:
- Terdapat 79 data duplikat yang benar-benar sama.
- Tidak ada data null.
"""

top_10_places = tourism.sort_values(by='Rating', ascending=False).head(10)

# Visualizing with seaborn
plt.figure(figsize=(10, 6))
sns.barplot(x=top_10_places['Rating'], y=top_10_places['Place_Name'], palette='viridis')
plt.title('Top 10 Places by Average Rating')
plt.xlabel('Average Rating')
plt.ylabel('Place Name')
plt.show()

"""Freedom Library menduduki peringkat pertama dengan rating tertinggi, diikuti oleh Desa Wisata Sungai Code Jogja Kota dan Kauman Pakualaman Yogyakarta."""

plt.figure(figsize=(10, 6))
sns.scatterplot(x=tourism['Price'], y=tourism['Rating'], color='blue')
plt.title('Scatter Plot: Price vs Rating')
plt.xlabel('Price')
plt.ylabel('Rating')
plt.show()

"""Dari scatter plot, terlihat bahwa meskipun harga bervariasi, sebagian besar destinasi memiliki rating tinggi (di atas 4), namun tidak ada pola yang jelas antara harga dan rating."""

import statsmodels.api as sm

# Menambahkan konstanta untuk model regresi
X = sm.add_constant(tourism['Price'])
y = tourism['Rating']

# Membuat model regresi
model = sm.OLS(y, X).fit()

# Melihat hasil ringkasan model regresi
print(model.summary())

"""Dalam analisis regresi, hasil menunjukkan bahwa koefisien untuk harga sangat kecil (7.296e-08), dan p-value sebesar 0.628 menunjukkan bahwa harga tidak berpengaruh signifikan terhadap rating destinasi wisata. Nilai R-squared yang sangat rendah (0.001) juga menegaskan bahwa harga hanya menjelaskan sedikit sekali variasi dalam rating.

**Harga tidak menjadi faktor yang signifikan dalam menentukan rating destinasi wisata.**
"""

rating_distribution = rating['Place_Ratings']
rating_counts = pd.Series(rating_distribution).value_counts().sort_index()

plt.figure(figsize=(8, 6))
rating_counts.plot(kind='bar')
plt.title('Distribution of Ratings')
plt.xlabel('Rating')
plt.ylabel('Count')
plt.xticks(rotation=0)
plt.show()

"""Dari grafik ini, dapat dilihat bahwa distribusi pemberian rating oleh user relatif merata, di mana setiap rating (1 hingga 5) memiliki jumlah yang hampir sama, sekitar 2000, dengan sedikit perbedaan antara setiap kategori rating.

# Data preparation

## Merge Dataset
"""

# Merge dataset
df_merge = pd.merge(rating, tourism, on='Place_Id', how='left')

"""## Menghapus kolom tidak relevan"""

df_clean = df_merge.drop(['Unnamed: 11','Unnamed: 12', 'Time_Minutes', 'Coordinate',	'Lat',	'Long', 'Rating', 'Price'], axis=1)

"""- Menghapus kolom yang tidak relevan untuk pembuatan model sistem rekomendasi.
- Pada Rating menggunakan kolom Place_Ratings dari dataset tourism_rating.csv karena menggambarkan interaksi user dalam memberikan rating terhadap destinasi.

## NaN value
"""

# cek missing value
df_clean.isnull().sum()

"""Pada data understanding terdapat NaN value, tetapi terdapat pada kolom Time_Minutes dan Unnamed: 11 sehingga data tersebut tidak digunakan dan menjadi tidak ada NaN value

## Drop/delete duplikat value
"""

df_clean = df_clean.drop_duplicates()

"""## Processing text"""

stop_words = set(stopwords.words('indonesian'))
stemmer = StemmerFactory().create_stemmer()

def preprocess(text):
    text = text.lower()                                  # Lowercase
    text = re.sub(r'[^\w\s]', '', text)                  # Remove punctuation
    text = re.sub(r'\d+', '', text)                      # Remove numbers (optional)
    tokens = text.split()
    tokens = [word for word in tokens if word not in stop_words]  # Remove stopwords
    text = ' '.join(tokens)
    text = stemmer.stem(text)                            # Stemming
    return text

df_clean['Description'] = df_clean['Description'].apply(preprocess)
df_clean['City'] = df_clean['City'].apply(preprocess)
df_clean['Category'] = df_clean['Category'].apply(preprocess)

df_clean.head()

print("Setelah dilakukan data preparation")

baris, kolom = df_clean.shape
print(f"Jumlah baris: {baris}")
print(f"Jumlah kolom: {kolom}")

"""## Pemisahan data (CBF dan CF)

### CBF
"""

df_cbf = df_clean.copy()
df_cbf.drop_duplicates(subset='Place_Id', inplace=True)
df_cbf.drop(['User_Id', 'Place_Ratings'], axis=1, inplace=True)
df_cbf.reset_index(drop=True, inplace=True)
df_cbf

tfidf = TfidfVectorizer()
tfidf_matrix = tfidf.fit_transform(df_cbf['Description'])

print(tfidf_matrix.shape)

cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)
cosine_sim

"""### CF"""

df_cf = df_clean.copy()
df_cf.drop(['Place_Id', 'Description', 'City', 'Category'], axis=1, inplace=True)

reader = Reader(rating_scale=(1, 5))
data = Dataset.load_from_df(df_cf[['User_Id', 'Place_Name', 'Place_Ratings']], reader)

trainset, testset = train_test_split(data, test_size=0.2, random_state=42)

"""# Model development

## CBF
"""

def get_recommendations(query_index, n_recommendations=5):
    place_name = df_cbf['Place_Name'][query_index]
    category = df_cbf['Category'][query_index]
    city = df_cbf['City'][query_index]
    description = df_cbf['Description'][query_index]

    # Tampilkan info awal
    print(f'Destinasi: {place_name}')
    print(f'Kategori: {category}')
    print(f'Kota: {city}')
    print(f'Deskripsi: {description}\n')
    print(f'{n_recommendations} Rekomendasi:\n')

    similarity_scores = list(enumerate(cosine_sim[query_index]))

    recommendations = []
    for idx, sim_score in similarity_scores:
        if idx == query_index:
            continue  # skip diri sendiri

        # Binary match: 1 jika sama, 0 jika tidak
        category_score = 1 if df_cbf['Category'][idx] == category else 0
        city_score = 1 if df_cbf['City'][idx] == city else 0
        description_score = sim_score

        # Hitung total skor akhir
        final_score = (0.6 * description_score) + (0.25 * category_score) + (0.15 * city_score)

        recommendations.append({
            'Recommended Destination': df_cbf['Place_Name'][idx],
            'Category': df_cbf['Category'][idx],
            'City': df_cbf['City'][idx],
            'Description Similarity': round(description_score, 4),
            'Category Score': round(category_score, 4),
            'City Score': round(city_score, 4),
            'Total Score': round(final_score, 4)
        })

    # Buat DataFrame dari hasil rekomendasi dan ambil n teratas
    recommendations_df = pd.DataFrame(recommendations).sort_values(by='Total Score', ascending=False)
    return recommendations_df.head(n_recommendations)

query_index = 21
recommendations = get_recommendations(query_index, n_recommendations=10)
recommendations

"""precision@10 (Category) = 10/10 = 1.0

precision@10 (Kota) = 9/10 = 0.9

precision@10 (Category & Kota) = 9/10 = 0.9

Terlihat bahwa hampir seluruh hasil memiliki kategori yang sama (pusat belanja) dan berada di lokasi yang sama (Jakarta), dengan deskripsi yang mengandung kesamaan tematik seperti “pasar”, “belanja”, “kawasan seni”, dan “kolektor”.

## CF
"""

# Gunakan SVD untuk matrix factorization
model = SVD()
model.fit(trainset)

predictions = model.test(testset)

# Fungsi rekomendasi berdasarkan matrix factorization
def get_mf_recommendations(user_id, top_n=5):
    place_names = df_cf['Place_Name'].unique()
    rated_places = df_cf[df_cf['User_Id'] == user_id]['Place_Name'].tolist()
    unrated_places = [place for place in place_names if place not in rated_places]

    pred_ratings = []
    for place in unrated_places:
        pred = model.predict(user_id, place)
        pred_ratings.append((place, pred.est))

    sorted_preds = sorted(pred_ratings, key=lambda x: x[1], reverse=True)[:top_n]
    return pd.DataFrame(sorted_preds, columns=['Recommended Place', 'Predicted Rating'])

# Contoh pemanggilan
get_mf_recommendations(user_id=1, top_n=10)

# Evaluasi: RMSE dan MAE
rmse(predictions)
mae(predictions)

"""Model untuk sistem rekomendasi Coolaborative Filtering menggunakan algoritma Singular Value Decomposition (SVD) mendapatkan skor evaluasi
- RMSE : 1.4485
- MAE : 1.22475
"""

